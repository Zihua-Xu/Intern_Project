import glob
import pandas as pd
import os
import datetime
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tqdm import tqdm
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

label_dirs = glob.glob('Label_csv/')  # 标签数据文件夹的路径
print(label_dirs)
label_files = []

for d in label_dirs:
    label_files.extend(glob.glob(f'{d}*.csv'))

label_times_files = {
    datetime.datetime.strptime(
        os.path.basename(f).split('_')[1].split('.')[0],  # 修正点在这里
        "%Y-%m-%d %H-%M-%S"
    ): f for f in label_files
}








def process_label_data(label_file):
    # 加载标签数据
    label_data = pd.read_csv(label_file)
    label_data['time'] = label_data['time'].apply(lambda x: int(x // 3))  # 重要：以xx行聚合
    
    # 自定义处理标签数据的函数
    def get_majority_action(group):
        if group.isnull().all().all() or (group.drop('time', axis=1) <= 0.3).all().all():  # 检查组是否全部为NaN或0，忽略时间列
            return "label empty"  # 如果是，返回一个特殊标记
        else:
            # 提取出现概率超过0.3的动作标签
            actions = group.drop('time', axis=1).columns[group.drop('time', axis=1) > 0.3].tolist()
            # 按照要求拼接成一个字符串
            action_str = ', '.join(actions)
            return action_str
    
    # 对每个时间段应用自定义函数
    aggregated_records = []  # 初始化一个空列表来收集所有的记录
    for name, group in label_data.groupby('time'):
        action = get_majority_action(group)
        aggregated_records.append({'time': name, 'Final Label': action})  # 将记录添加到列表
    
    aggregated_labels = pd.DataFrame(aggregated_records)  # 使用收集到的记录一次性创建DataFrame
    return aggregated_labels

# 调用函数并传入标签文件路径
processed_labels = process_label_data("")
